---
layout: post
title:  "Forward Forward algorithm"
date:   2023-02-19
author: red1108
tags: [AI, Deep Learning, Machine Learning]
---
## 서론

인공지능의 대부 Hinton교수가 새로운 신경망 학습 방법을 고안했다. 2022년 12월 27일에 아카이브에 올라온 논문이라 글 작성 시점에서 아직 따끈따끈한 논문이다. 인공지능의 대부가 쓴 논문인 만큼 벌써 조금씩 인용이 되고 있다. 과연 Hinton교수가 이번에 발명한 학습방법은 어떤 것인지 살펴보도록 하자.

> 본 글은 Hinton교수님의 Forward Forward algorithm 논문[1] 중에서도 Forward Forward의 작동 원리만을 이해하는 것에 초점을 두고 정리하였다. 논문 전체 내용을 정리하는 목적이 아니므로 빠진 내용들이 있다. FF에 대해 더 궁금하다면 논문 원문을 살펴보는 것을 강력하게 추천한다. FF에 대한 Hinton교수님의 다양한 인사이트를 엿볼 수 있을 것이다.

## 왜 새로운 학습 방법을 찾아야 하는가

그동안 안정적으로 사용되어진 딥 러닝의 주된 학습 방식은 오류 역전파 알고리즘(Back Propagation, BP)방식이다. 하지만 BP방식도 잘 알려진 어려 문제점을 가지고 있다

1. 기울기 소실 문제

2. 과적합 문제

3. 로컬 미니멈 문제

4. 계산 비용 문제

상술한 문제들은 많은 연구들을 통해 해결법이 잘 제시되어 있는 편이지만, 좀 더 근본적인 문제점이 남아있다. 인공지능의 궁극적인 목표는 인간의 뇌와 유사한, 인간 수준 또는 그 이상의 문제해결 능력을 모방하는 것이다. 그런데 현재까지 알려진 바로는 우리 뇌는 오류 역전파 알고리즘으로 학습하지 않는 것 처럼 보인다. 왜냐하면 오류 역전파 알고리즘을 구현하기 위해서는 각 계층에서 일어나는 모든 계산과정의 gradient를 기록해야 하는데 우리 뇌에서는 그 정보를 저장하는 기관이 관찰되지 않았기 때문이다[2]. 이외에도 해당 논문에서는 뇌가 BP를 기반으로 학습하지 않는다는 더 많은 근거들을 제시하고 있으니 궁금한 사람은 찾아보길 바란다.

사실 현재의 딥러닝 방법론이 실제 뇌와 다른 점은 너무 많아서 나열하기도 힘든 수준이다. 뇌는 loss function을 정의하지도 않고 각각의 뉴런에서 계산이 분산되어 자연스러운 상호작용만으로 학습을 이뤄낸다. 그런데도 희소한 데이터만을 가지고 뛰어난 성능을 낸다. 에너지 소모율로 따진 효율성도 컴퓨터보다 훨씬 앞선다.

> 물론 인간 수준의 인지능력과 문제해결 능력을 갖춘 인공지능을 만들기 위해서 꼭 뇌의 기능을 완벽하게 규명할 필요는 없다. 이는 마치 새와 비행기의 관계와 같다. 비행기의 형태는 새의 날개를 모방하여 만들어졌지만, 날개의 퍼덕임이 아니라 엔진의 추력으로 비행한다. 원하는 목표를 달성하기 위해 어느 정도의 모방은 좋지만, 대상에 대한 완벽한 규명이 필수는 아니라는 점을 짚고 넘어가고자 한다.

이러한 문제점들로 인해 BP를 대체할만한 다양한 방법들이 연구되었지만, 아직까지 BP만한 방법은 발견되지 않았다고 보아도 무방하다. 그리고 이번에 나온 Hinton교수의 Forward Forward논문도 같은 결의 연구이지만, Forward Forward 역시 Backpropagation보다 나을지는 아직 모르는 일이다. 다만 Hinton교수의 연구라 관심을 많이 받는 만큼 발전시켜보려는 시도 또한 많이 이뤄질 것이고 쓸모 있는지 없는지 비교적 빨리 평가될 것이라 생각한다.

서론이 길었으니 이제 Forward Forward Algorithm에 대해 소개해 보겠다.

# Forward Forward Algorithm

## 간략한 소개

Forward Forward Algorithm(FF)는 Hinton교수가 제안한 다층 신경망을 학습하는 새로운 방법이다. 퍼셉트론을 기반으로 한 다층 퍼셉트론의 구조는 우리가 아는 그대로이다. 학습 방법만 다른 것이다.

오차 역전파 알고리즘(Backpropagation, BP)는 신경망을 순방향으로 훑으며 계산과정을 기록해나가고 뒤에서부터 시작해서 미분계수를 구하는 두 가지 Pass로 구성되어 있다. 이를 Forward pass & Backward pass로 부르자.

새롭게 제안된 방식인 Forward Forward알고리즘은 두 번의 Forward pass로 구성되어 있다. 그래서 알고리즘 이름이 Forward Forward인 것이다. 첫 번째 Forward pass는 positive data에서의 신경망의 **활성도**를 키우고 두 번째 Forward pass는 negative data에서 신경망의 **활성도**를 낮추는 역할이다.

> 우리 뇌에서 뉴런의 흥분은 전기적인 신호로 표현된다. 뉴런이 항상 흥분하는 것은 아니며 가지돌기로부터 받은 신호로부터 흥분의 여부가 결정된다. 어떨 때에 얼마나 흥분할지 결정하는것이 중요한 것이다.

여기서 말하는 신경망의 **활성도**는 논문에서 후술할 goodness function과 관련된다.

MNIST의 경우로 예시를 들어보자. 숫자 5가 5라고 제시하는 data는 positive data이다. 그리고 이 경우에는 신경망의 활성도가 높아지는 방향으로 학습이 진행된다. 숫자 7이 2라고 제시하는 data는 negative data이다. 이 경우엔 신경망의 활성도가 낮아지는 방향으로 학습이 진행된다. 모든 학습을 거친 다음 숫자 8사진을 이용해 inference를 진행해 보자. 만약 학습이 올바르게 진행되었다면 숫자 8이 0이라고 하는 경우부터 숫자 8이 9라고 하는 총 10가지의 경우들 중에서 제일 신경망의 활성도가 높아지는 경우는 숫자 8이 8이라고 말하는 경우일 것이다. 따라서 FF방식으로 학습된 모델은 숫자 8사진을 보고 이 숫자가 8임을 알아낼 수 있다.

아직은 간단한 문제에만 적용 가능하며, 논문에서도 MNIST와 CIFAR-10의 경우만 다루었다. 그리고 error rate는 CNN기반 오차 역전파 알고리즘과 비교해 보았을때 비슷하거나 살짝 높았다. 처음 제시된 개념인데도 거의 비슷한 정도의 error rate를 보인다는 점에서 발전 가능성이 높다고 판단된다.

이제 FF를 좀 더 자세히 알아보도록 하자.

## Positive & Negative Data

FF에서 사용하는 데이터는 두 가지 종류로 구분된다.

Positive data는 *올바른 데이터*라고 생각하는게 이해하는데 편하다. MNIST의 경우엔 사진과 라벨이 일치하는 데이터 쌍에 해당한다.

Negative data는 위와 대조적으로 *잘못된 데이터*라고 생각하면 된다. MNIST에서는 사진과 라벨이 일치하지 않는 데이터 쌍에 해당한다.

Positive data는 쉽게 제작할 수 있지만 Negative data를 만드는 것은 고민해보아야 할 문제이다. 논문에서는 Unsupervised FF와 Supervised FF 각각의 경우에 대하여 Negative data를 만드는 방법을 소개한다.

### Negative Data in Unsupervised FF

이미지 변형

### Negative Data in Supervised FF

라벨 임베딩

**Positive data, Negative data 비교하여 설명하자. 사진도 첨부하자.**

## Goodness Function

Forward Forward Algorithm의 핵심은 Positive data에서는 goodness function의 값을 키우고, Negative data에서는 goodness function의 값을 작게 만드는 것이다.

goodness function를 어떻게 번역할지는 아직 합의되지 않았지만, '적합도', '활성도', '흥분도' 정도로 이해하면 될 것 같다. 앞으로는 그냥 goodness라고 적겠다.

## Negative data를 만드는 법

두가지 방식 소개

## Negative data를 만드는 법

두가지 방식 소개

## FF의 장점

Forward Forward Algorithm이라고 해서 Backpropagation알고리즘이 가진 문제점을 다 해결한 것은 아니다. 그래도 의미 있는 해결점이 몇가지 있다.

1. **BP에서 chain rule을 적용하기 위해 계산 과정에서 저장하는 많은 값들이 필요하지 않다.**
    FF는 각 레이어마다 학습을 진행하기 때문에 자연스럽게 방대한 계수를 저장하고 있을 필요가 없다.

2. **모델 중간에 Blackbox가 끼어있어도 여전히 학습이 가능하다.**
    BP는 모든 계산과정을 기록해야 하므로 Blackbox가 끼어있으면 학습이 불가능하다. 그러나 FF는 각 레이어의 학습에는 오로지 그 레이어만 영향을 주므로 Blackbox가 끼어있어도 학습이 가능하다.

## Discussion

1. 확장성의 문제
2. negative data는 어떻게 만들지
3. inference를 다 해보아야 하나?
4. 복잡도
    메모리 복잡도 따지는 링크 걸어주자

## 글을 마치며

16페이지짜리 논문에서 다루지 않는 내용이 꽤 있다. 몇가지를 언급해 보자면

1. Recurrent FF

2. Negative data를 신경망으로부터 생성하는 방법

원문이 되는 (Hinton, 2022)[1] 논문에서는 인공지능 대부의 insight를 엿볼 수 있고, 어떤 관점에서 FF를 적용시켜보려고 했는지 훨씬 많은 내용이 담겨 있다. 이 글을 읽고 FF에 흥미가 생겼다면 위 논문을 직접 읽어보길 권한다.

## Reference

[1] 제프리 힌튼 FF논문

[2] (Lillicrap et al., 2020; Richards and
Lillicrap, 2019; Guerguiev et al., 2017; Scellier and Bengio, 2017
